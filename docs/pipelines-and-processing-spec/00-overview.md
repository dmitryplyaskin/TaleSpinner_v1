# TaleSpinner — Pipelines + Pre/Post Processing Spec (v0.1) — Overview

> Статус: **draft** для обсуждения.  
> Цель: зафиксировать архитектуру пайплайнов и пре/постпроцессинга, совместимую с текущим chat-core флоу, чтобы дальше согласовать API и начать реализацию.

> Примечание: это часть спеки, выделенная из монолита `pipelines-and-processing-spec-v0.1.md`.

## Контекст (связь с текущим кодом)

На дату `2026-01-20` фактический флоу описан в `../chat-flow-from-code-2026-01-20.md`.

Текущее состояние (важно для совместимости):

- Backend собирает prompt и стримит SSE (`llm.stream.*`).
- `pipeline_runs` / `pipeline_step_runs` уже существуют, но шаги фиксированы (`pre` + `llm`) и выступают как лог.
- Канонический promptable текст для LLM сейчас фактически берётся из `promptText` (denorm кэш выбранного варианта).
- `blocksJson` присутствует в схеме, но почти не участвует в генерации/стриме.

Эта спека описывает **целевую архитектуру v1**, которая “доразвивает” текущий подход без ломки инвариантов.

## Цели

- **Backend-first orchestration**: сервер является источником правды о том, что пошло в LLM и как получился результат.
- **Наблюдаемость**: уметь объяснить “почему такой ответ” через `pipeline_runs`, `pipeline_step_runs`, `llm_generations` и (опционально) snapshot prompt.
- **Расширяемость**: заложить архитектуру под RAG/tool/post-processing, не переписывая историю в БД и не усложняя UI.  
  Уточнение: в v1 **реализуем** pre/post вокруг существующего chat-core, а `rag`/`tool` **только резервируем** (план на v2+).
- **Безопасная гибкость**: пайплайны могут влиять на prompt и результат текущего ответа, но влияние должно быть контролируемым (см. policy мутаций).

## Non-goals (v1)

- Полный DAG/граф зависимостей шагов (в v1 — линейная последовательность).
- Исторические “переписывания” чата (compaction/summary с заменой сообщений) по умолчанию.
- Потоковый (streaming) рендер и инкрементальное обновление `blocksJson` как обязательная фича.
- Полноценная реализация `rag`/`tool` шагов (retrieval/tools инфраструктуры в проекте пока нет; это план v2+).
- Сложные tool↔LLM циклы/петли (agent loop) как must-have. При этом **несколько LLM-вызовов подряд** внутри одного `PipelineRun` допустимы и описаны ниже.

## Термины

- **Pipeline**: описание процесса (набор шагов + настройки + условия), который выполняется при определённом триггере.
- **PipelineProfile**: сохраняемая конфигурация (набор “активных” пайплайнов), которую пользователь может:
  - выбрать как глобальный default,
  - закрепить (override) на уровне `entityProfile` и/или конкретного `chat`.
  PipelineProfile — это **конфиг**, а не выполнение.
- **Active PipelineProfile**: PipelineProfile, который фактически используется для данного `chat` (резолвится по правилу приоритетов: `chat override` → `entityProfile override` → `global default`).
- **PipelineRun**: конкретный запуск Pipeline.
- **PipelineStepRun**: выполнение одного шага внутри PipelineRun, с логом входа/выхода/ошибок/тайминга.
- **Step**: атомарная стадия исполнения, например `pre`, `rag`, `llm`, `post`, `tool`.
- **Generation**: попытка получить/обновить текст ассистента через LLM (стрим/аборт/метрики).
- **PromptDraft**: “рабочий” prompt, который реально будет отправлен в LLM (system + history + prompt-time инъекции/augmentation + policy), но не обязан быть БД-сущностью.  
  Примечание: `rag`/`tool` как источники инъекций зарезервированы на v2+.
- **OutputDraft**: “рабочий” результат (накопленный assistant text + blocks/meta), который будет сохранён в БД в конце.
- **Mutation**: изменение состояния, которое шаг(и) пайплайна пытаются применить (к prompt-time или к каноническому состоянию).
- **Session (Artifact Session)**: “место жизни” persisted-артефактов для пайплайнов в рамках конкретного чата.
  - v1: сессия **строго chat-scoped** (ключ `chatId`), ветки не учитываем ради упрощения.
  - сессия — это persisted состояние (в БД), но в рантайме materialize’ится в `SessionView` (словарь `tag -> { value, history, meta }`) для шагов и Liquid.
- **PipelineArtifact**: универсальная единица “вывода/контента/памяти”, созданная пайплайном. Артефакт может:
  - отображаться в UI в разных местах (`uiSurface`),
  - участвовать или не участвовать в prompt (`visibility`),
  - жить как “эпизодический” (на один run) или “долговременный” (retention).
- **ArtifactAccess**: доступность артефакта для других пайплайнов/шаблонов:
  - `run_only` — существует только внутри текущего `PipelineRun` (не адресуется как `art.<tag>`, не требует уникального `tag`)
  - `persisted` — сохраняется и доступен другим пайплайнам/шаблонам по `tag` через `art.<tag>` (tag уникален)
- **ArtifactVisibility**: участие артефакта в prompt/UI:
  - `prompt_only` — участвует в prompt, не показывается пользователю
  - `ui_only` — показывается пользователю, не участвует в prompt
  - `prompt_and_ui` — и участвует в prompt, и показывается
  - `internal` — не участвует в prompt и не показывается в UI; может быть:
    - `access=run_only` (внутренний промежуточный результат шага),
    - или `access=persisted` (служебный результат для других пайплайнов/валидаторов/тул-обработки, но не для UI/prompt).
- **UiSurface**: “поверхность”/место отображения артефакта:
  - `chat_history` — внутри истории чата (как сообщение/блок)
  - `panel:<id>` — отдельный UI-виджет/панель (например `panel:rpg_state`)
  - `feed:<id>` — отдельная лента/поток (например `feed:commentary`)
  - `overlay:<id>` — оверлей/всплывающая поверхность (опционально)
- **Augmentation**: частный случай артефакта: промежуточный “prompt-only” контент (план/скретчпад/CoT-подобная заготовка), который используется **только для одной** последующей генерации и **не сохраняется** как сообщение истории.
- **PipelineState**: частный случай артефакта: долговременное состояние/память (например: “игровое время”, “локация”, “активные персонажи”), доступное другим шагам/пайплайнам как `art.<tag>`.

## Инварианты (обязательные правила v1)

### Backend source of truth

- Истина истории — в БД: `chat_messages` + выбранный `message_variants` (если включены).
- Истина процесса — в БД: `pipeline_runs`, `pipeline_step_runs`, `llm_generations`.
- Frontend не формирует финальный prompt (может показывать локально optimistic UI, но не решает политику контекста).

Уточнение v1 (совместимость с текущим chat-core):

- “Вызов LLM”/стриминг генерации в v1 рассматривается как **существующий механизм** backend-а (chat-core), который мы не переписываем ради пайплайнов.
- Пайплайны в v1 добавляют **обвязку** вокруг генерации: `pre` до вызова и `post` после `done`, не меняя протокол стрима и базовую механику flush в БД.

### Promptable truth: `promptText`

- Канонический “promptable” слой истории в v1 берётся из **`promptText` выбранного состояния** сообщений.
- При этом поверх истории допускаются **prompt-time** модификации в `PromptDraft` (augmentation / system notes / prompt-only replace и т.п.; RAG/tool — v2+), которые **не становятся частью истории**.
- `blocksJson` предназначен для UI и расширений; он может не совпадать с `promptText`.

> Дополнение (перепроектирование ради расширяемости): если мы вводим `PipelineArtifact` как first-class сущность,
> то `blocksJson` становится “быстрым UI-представлением” для `uiSurface=chat_history` (denorm),
> а источником правды о том, что создано пайплайном, становятся артефакты.

Уточнение (важно для кейса “pipeline переписывает user-сообщение”):

- Инвариант `promptText` остаётся: в prompt попадает **только `promptText` выбранного состояния**.
- Но “выбранное состояние” может быть:
  - исходным user-вводом (как есть),
  - **вариантом** user-сообщения (например `kind=normalized|rewritten`), выбранным сервером по policy пайплайна,
  - либо prompt-time проекцией (если это не должно становиться каноном истории).

### Private reasoning / CoT

- В системе допускаются “скретчпад/CoT-подобные” артефакты для улучшения качества, но они считаются **private/internal**:
  - **не показываются пользователю**,
  - **не попадают в `promptText` истории**,
  - по умолчанию **не логируются как сырой текст** в БД (только redacted/сводка/хеш), чтобы не хранить лишнее и не утекать.
- Практическая рекомендация: просить модель не “raw chain-of-thought”, а структурированный **план/заметки** (“working notes”) в формате, который безопасно использовать как `Augmentation`.

### Ограничение мутаций истории

- В v1 пайплайны **не переписывают прошлую историю** как часть обычного “одного хода” (turn).
- Допускаются только:
  - **prompt-time трансформации** (влияние на PromptDraft без изменения БД истории),
  - **каноническое сохранение** результата текущего ответа (assistant variant/message),
  - отдельные явно выделенные операции (см. “Исторические трансформации”, v2+ или opt-in).

## Уточнение: `branchId` vs chat-scoped Session (v1)

UI может иметь представление “веток”, но в v1 это сознательное упрощение:

- persisted-артефакты живут в **одной сессии на чат** (`sessionId = chatId`) и **не разделяются по `branchId`**.
- `branchId` остаётся в `PipelineRunContext` как часть корреляции/совместимости и будущего расширения, но **не влияет** на storage артефактов в v1.
- v2+ (опционально): возможен переход к `sessionScope = branch` или гибридной модели, если ветки станут обязательными для UX пайплайнов.

